* Research todo lists

** TODO implement DPF on Spark
** TODO discrete state converges to the state of fault: bearing data
- GP Bayesian PF classification on top up Spark
- either build HMM for time series directly or build HMM for features extracted from time series
- the reason using transition matrix between different modes is to make transition matrix time-variant
  to make transition probability become higher when the mode currently with high weight indicates a poor
  observation probability which means the underlying mode has switched
- each batch of stream may consist of several sub time series generated by different modes, therefore
  the description of this batch should be a weighted combination of all modes
- use several Gaussian processes each representing a mode characterized by their different kernel function
- multiple modes have the same initial mode probability
- use streaming data as input, D-stream implementation; particles set should be built by RDDs
  not the input observe state, because taking one observe a time would be too fine-grained for a D-stream
- the probability of one mode will eventually dominate indicating the undlying mode of
  data generator
- after trainning the model discrete state is the ony state that needs to be tracked, parameters of transition matrix
  are treated as non-static and need to be estimated too in order to capture the mode switch trend and make corresponding
  adjusts to transition probabilities increasing the converge rate
- use logistic regressiong model for transition matrix
- transition matrix should be diagnol major, since mode switch does't happen a lot,
  for any moment the probability of staying in current mode should be large
- use bearing fault data as an experiment for real-time mode detection
- real-time stream data processing by DPF and D-stream
- change point detection, particle filtering, multi-mode model
- train base model off-line then update or improve the model on-line
- bearing fault data, load data per second into a D-stream, extract its features,
  given the feature estimate underlying fault mode, real-time fault detection using spark
- particle filtering time series data using spark
- Bearing fault: my original data model: y_n=g(x_n), x_n=f_q(x_{n-1}), q_n=Q * q_{n-1}, hidden
  continuous states x and discrete mode states q and model parameters are all need to be estimated.
  my new model: extract feature set f_n from each block of {y_i}_n, treat feature set as observes,
  discrete mode states q and model parameters are hidden states. Given each mode state q, there is
  an observation model defining an observation distribution and there is also a transition matrix for
  q. The aim is to use particle filter estimating distributions for q and parameters given the extracted
  feature variables. Need to define observation models for different mode q and transition matrix
  between different q. The transition models for each parameter can be approximated by normal distributions.
  IMM is in fact a mixture model, the distribution for discrete mode variable q at each time step is
  actually a set of weights for each mode model. The benefit of tracking discrete state q is that
  at each time step, instead of initializing probabilities for each mode, probabilities can be propagated
  from distribution of q of previous time step.
- Implement operators for D-stream, data preprocessing, data decomposition, data prediction for future trends
  (trend prediction is vital step in anomaly detection)
- IMMPF, each mode of PF runs on a compute node. Ensemble clustering, incremental batch learning through D-stream.
  Ensemble methodology is to build a predictive model by integrating multiple models.
- Real-time time series classification using IMM particle filter on Spark, real time data mining, streaming processing
  For each input D-stream, estimate the value of discrete mode variable q to determine which underlying model
  the current D-stream belongs to and this complete the classification.



** TODO compare Mapreduce and Spark implementations of DPF
** TODO sparkstreaming implementation
** TODO realtime particle fitering using spark stack

* Notes about Spark

** RDD
=RDD='s =iterator= method returns an =iterator= on one partition of the RDD. It firstly check
the =storageLevel= of this =RDD=, then decides whether the partition can be returned directly
or need to compute from its parent =RDD= or can be load from a file because of it has been
check-pointed.

*** All transformation operations are lazy
Take map operation as an example. The parent =Rdd= maps to a =MappedRdd= which stores
the parent =Rdd= as its dependency and overrides the =compute= method that will call
map function inside it. The Mapped =Rdd= is be returned and the actual data transformation
will not be executed until =compute= method is called. So the what =MappedRdd= does is to
remember its parent =Rdd= and associated map operation. Within =compute= method =MappedRdd='s
firstParent mehtod returns its parent =Rdd= on which iterator method is called (this
method will call =CacheManager= object's =getOrCompute= method). And by taking a partition parameter
and its corresponding =TaskContext= parameter an iterator of one
partition of parent =Rdd= will be returned. In the end, the returned iterator will apply
map operation to every element of its =Rdd= partition. Transformations operation are lazy,
they don't initialize a Spark job.

*** Action operation
Action operations initiate a Spark job. The main entry point for all actions is the =runJob= method
defined in =SparkContext= class. It runs a function on a given set of partitions in an =RDD=
and pass the results to the handler function.
Take reduce action for example. In reduce method there are two function: function =reducePartition=
is a reduce processing function whose type is =Iterator[T] => U=, it takes a partition's iterator
as input and apply reduce action on this partition; function =mergeResult= is a =resultHandler=
function whose type is =(Int, U) => Unit= where its first parameter is the index of partition,
this function applies reduce action on all the results of partitions and obtains a global result.
In the end of reduce method, =runJob= method of =SparkContext= object will be called; this method
has a =partitions: Seq[Int]= parameter which can be used to set a subset of partitions of =RDD=
on which the action operation runs. The method actually delegate the job to class =DAGScheduler='s
=runJob= method which then invokes =submitJob= method. Method =runJob= returns =Unit=, it will
blocks until the job completes. The =jobResult= is defined as =var= and passed into the closure
=mergeResult= and get updated when job runs. The method =submitJob= returns a =jobWaiter= object
to method =runJob=, its =awaitResult= method will listen to the corresponding running
job (with the same =jobId=), it returns when all tasks (i.e. =partitions.size= tasks) complete
indicating the job has succeeded. The =JobSubmitted= object (message) with the same =jobId= is then
passed to =DAGSchedulerEventProcessActor=. Upon receiving this message, the
=dagScheduler.handleJobSubmitted= method is called. This method will recursively call =submitStage=
method until reach the first stage of this job, then starts to do tasks in first stage and then
second until the final stage whose tasks corresponds to this reduce action. Tasks are spawned in
=submitMissingTasks= method by creating =ShuffleMapTask= or =ResultTask= objects, each object
initialized with one partition of =RDD=. So for each spark operation, there are =numPartitions=
=ShuffleMapTask= or =ResultTask= objects.

*** Job, Stage and Task
A stage is a set of independent tasks all computing the same function that need to run as part
of a Spark job, where all the tasks have the same shuffle dependencies. Each DAG of tasks run
by the scheduler is split up into stages at the boundaries where shuffle occurs, and then the
=DAGScheduler= runs these stages in topological. Each Stage can either be a shuffle map stage,
in which case its tasks' results are input for another stage, or a result stage, in which case
its tasks directly compute the action that initiated a job.
Task is a unit of execution of a Spark job, tasks performing same operations run on partitions
of a =RDD= in parallel. There are two kinds of task in Spark:
=ShuffleMapTask= and =ResultTask=. A Spark job consists of one or more stages. The very last stage
in a job consists of multiple =ResultTasks=, while earlier stages consist of =ShuffleMapTasks=.
A ResultTask executes the task and sends the task output back to the driver application.
A =ShuffleMapTask= executes the task on one partition of =RDD= and divides the task output to
multiple buckets (based on the task's =partitioner= specified in the =ShuffleDependency= for
output shuffle if stage is a map stage). =TaskContext= containing task information (e.g.
=stageId=, =partitionId=, callback function upon task completes), is passed to =runTask= method.
In a =ShuffleMapTasks= object, its =split= field equals =rdd.partitions(partitionId)=,
its =numOutputSplits= field equals =dep.partitioner.numPartitions=. Its =runTask= method will
run a =for= loop, at the beginning of which =RDD.iterator= method is called which compute and
return an =iterator= on the partition of current task, then the loop iterates over each element
of =split= (partition) and shuffles each element to one of the output buckets depending element's
key value.
A =ResultTasks= object is initialized by passing an action operation function to it. Its
=runTask= method takes =TaskContext= parameter and then delegate the task to action operation
function by passing =rdd.iterator= and =TaskContext= to it. Upon completion of the task
a call back function is invoked on =TaskContext= object.

** PySpark
PySpark is built on top of Scala/Java Spark. PySpark re-uses a lot of
functionality provided by Spark, including its scheduling, broadcast,
checkpointing, networking, fault-recovery, and HDFS access. Python RDD is a
wrapper for Java RDD while expose python API for Spark transformations and
actions.  In your Python program, SparkContext uses Py4J to launch a JVM and
create a JavaSparkContext, Python SparkContext is a wrapper for
JavaSparkContext.  Py4J is only used on the driver for local communication
between the Python and Java SparkContext objects.  RDD transformations in Python
are mapped to transformations on PythonRDD objects in Java. On remote worker
machines, PythonRDD objects launch Python subprocesses and communicate with them
using pipes, sending the user's code and the data to be processed. User-defined
functions (e.g. lambdas or functions passed to map, flatMap) are serialized
using PiCloud's cloudpickle library and shipped to remote Python workers.
PySpark pipelines transformations by composing their functions. When using
PySpark, there's a one-to-one correspondence between PySpark stages and Spark
scheduler stages. Each PySpark stage corresponds to a PipelinedRDD instance.

* Notes about Mllib

** SVMWITHSGD
SVMModel class represents trained model created by static train method in =SVMWITHSGD=
class which represents SVMwithSGD algorithm. The method train creates a new SVMWITHSGD
object which then calls its run method that will return a SVMModel ojbect. The SVMWITHSGD
class has an optimizer member who is initialized with a gradient object for computing gradient
and a updater object for updating weight given gradient. The optimizer ojbect will call its
optimize method within the run method and the optimize method will iteratively compute gradient
and update weights. The run method is defined in GeneralizedLinearAlgorithm class inherited
by SVMWITHSGD class. The optimizer object is a type of GradientDescent class which implements
Optimizer interface. The optimize method calls runMiniBatchSGD method defined in GradientDescent
class to run gradient descent algorithm in parallel.

* Notes about machine learning

** Six major steps
- Set a goal
- Pick features
- Model training
- Measure lift
- Practice
- Predict

** Data mining flow
- Get sample data set from DBMS, HDFS
- Clean and explore data (SQLite, Pandas, ETL, R)
- Build model (R, scikit-learn)
- Scale model out (Mahout, MapReduce)
- Apply model in real-time
* Implementations of distributed particle fiters on Spark
